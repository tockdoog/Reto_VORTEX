# =================================================================
# SERVICIO ORQUESTADOR DE CHURN
# =================================================================
# Este archivo COORDINA todo el flujo de predicci贸n de churn.
# Es el "manager" que usa el ML Service y guarda en MongoDB.

from datetime import datetime
from typing import Optional, List
from app.services.ml_service import ml_service
from app.db.mongodb import get_database
from app.models import ChurnPredictionModel, FeedbackModel
from app.schemas.churn import (
    PredictChurnRequest,
    PredictChurnResponse,
    ChurnStatusResponse,
    FeedbackRequest,
    FeedbackResponse,
    DailyChurnStatsResponse
)

# 
#  CONCEPTO: Orquestador (Orchestrator)
# 
# Un orquestador es como el "director de orquesta".
# Coordina diferentes servicios para completar una tarea.
#
# Flujo t铆pico:
# 1. Recibe datos del endpoint
# 2. Llama al ML Service para calcular
# 3. Guarda el resultado en MongoDB
# 4. Retorna la respuesta formateada
#
# Esto se conoce como "Separation of Concerns" (Separaci贸n de Responsabilidades)
# 


class ChurnService:
    """
    Servicio orquestador de Churn Prediction.
    
    Este servicio NO hace c谩lculos de ML directamente.
    Coordina entre el MLService y la base de datos.
    """
    
    def __init__(self):
        """Constructor vac铆o. La configuraci贸n ya est谩 en otros lados."""
        pass
        # 'pass' en Python significa "no hacer nada"
        # Equivalente en TS: constructor() { }
    
    
    async def predict_churn(
        self, 
        request: PredictChurnRequest
    ) -> PredictChurnResponse:
        """
        Predice el churn de un usuario y guarda el resultado.
        
        FLUJO:
        1. Llamar al ML Service para calcular
        2. Guardar la predicci贸n en MongoDB
        3. Retornar respuesta formateada
        """
        
        # 
        # PASO 1: Calcular probabilidad con el ML Service
        # 
        churn_prob, risk_level, risk_factors = ml_service.predict_churn(
            request.features
        )
        # Esto DESEMPAQUETA la tupla en 3 variables separadas
        # En JS ser铆a: const [prob, level, factors] = predict(...);
        
        # 
        # PASO 2: Generar recomendaci贸n
        # 
        recommendation = ml_service.generate_recommendation(
            churn_prob,
            risk_level
        )
        
        # 
        # PASO 3: Guardar en MongoDB
        # 
        db = get_database()
        collection = db["churn_predictions"]
        # En MongoDB, una "collection" es como una tabla SQL
        # Equivalente en SQL: SELECT * FROM churn_predictions
        
        prediction_doc = {
            "user_id": request.user_id,
            "churn_probability": churn_prob,
            "risk_level": risk_level,
            "risk_factors": risk_factors,
            "features_used": request.features,
            "model_version": ml_service.model_version,
            "created_at": datetime.utcnow()
        }
        
        # insert_one() guarda UN documento en MongoDB
        # 'await' espera a que termine de guardar
        await collection.insert_one(prediction_doc)
        
        # 
        # PASO 4: Retornar respuesta
        # 
        return PredictChurnResponse(
            user_id=request.user_id,
            churn_probability=churn_prob,
            risk_level=risk_level,
            risk_factors=risk_factors,
            recommendation=recommendation,
            timestamp=datetime.utcnow()
        )
        # Esto crea una instancia del schema PredictChurnResponse
        # Pydantic validar谩 autom谩ticamente que todo sea correcto
    
    
    async def get_churn_status(
        self, 
        user_id: str
    ) -> Optional[ChurnStatusResponse]:
        """
        Obtiene el 煤ltimo status de churn de un usuario.
        
        Este es el endpoint que el Dashboard llamar谩 para saber
        si debe mostrar el popup de "隆No te vayas!"
        
        RETORNA:
        - ChurnStatusResponse si encuentra datos
        - None si el usuario no tiene predicciones
        """
        
        db = get_database()
        collection = db["churn_predictions"]
        
        # Buscar la predicci贸n MS RECIENTE de este usuario
        prediction = await collection.find_one(
            {"user_id": user_id},  # Filtro: WHERE user_id = ...
            sort=[("created_at", -1)]  # Ordenar por fecha DESC
        )
        # find_one() retorna UN solo documento (o None)
        # -1 significa DESCENDENTE (m谩s reciente primero)
        # 1 ser铆a ASCENDENTE (m谩s antiguo primero)
        
        if not prediction:
            return None
            # Si no hay predicci贸n, retornar None (null en JS)
        
        # Si s铆 hay, formatear la respuesta
        show_popup = ml_service.should_show_exit_popup(
            prediction["churn_probability"]
        )
        
        popup_message = None
        if show_popup:
            popup_message = "隆Espera! Tenemos un 20% de descuento para ti "
        
        return ChurnStatusResponse(
            user_id=user_id,
            churn_probability=prediction["churn_probability"],
            risk_level=prediction["risk_level"],
            last_updated=prediction["created_at"],
            show_exit_popup=show_popup,
            popup_message=popup_message
        )
    
    
    async def register_feedback(
        self, 
        request: FeedbackRequest
    ) -> FeedbackResponse:
        """
        Registra el feedback de una intervenci贸n.
        
        Cuando el usuario acepta/rechaza una oferta en el Dashboard,
        guardamos esa informaci贸n para mejorar el modelo en el futuro.
        """
        
        # 
        # Buscar la 煤ltima predicci贸n para saber el score
        # 
        db = get_database()
        predictions_coll = db["churn_predictions"]
        
        last_prediction = await predictions_coll.find_one(
            {"user_id": request.user_id},
            sort=[("created_at", -1)]
        )
        
        churn_prob = last_prediction["churn_probability"] if last_prediction else 0.0
        
        # 
        # Guardar el feedback
        # 
        feedback_coll = db["feedback"]
        
        feedback_doc = {
            "user_id": request.user_id,
            "prediction_churn_prob": churn_prob,
            "intervention_type": request.intervention_type,
            "user_action": request.user_action,
            "timestamp": datetime.utcnow()
        }
        
        await feedback_coll.insert_one(feedback_doc)
        
        return FeedbackResponse(
            message="Feedback registrado exitosamente",
            user_id=request.user_id,
            saved_at=datetime.utcnow()
        )
    
    
    async def get_daily_stats(
        self, 
        days: int = 30
    ) -> List[DailyChurnStatsResponse]:
        """
        Obtiene estad铆sticas diarias de churn.
        
        Este endpoint es para el gr谩fico de barras del Dashboard:
        "D铆as vs Probabilidad de churn y Tickets"
        
        PARMETROS:
        - days: Cu谩ntos d铆as hacia atr谩s consultar (por defecto 30)
        
        RETORNA:
        Lista de estad铆sticas por d铆a.
        """
        
        # TODO: Implementar agregaciones de MongoDB
        # Por ahora retornamos datos dummy para que el Dashboard funcione
        
        from datetime import timedelta
        
        stats = []
        today = datetime.utcnow()
        
        for i in range(days):
            date = today - timedelta(days=i)
            
            # Generar datos aleatorios realistas
            import random
            stats.append(
                DailyChurnStatsResponse(
                    date=date.strftime("%Y-%m-%d"),
                    avg_churn_probability=round(random.uniform(0.4, 0.8), 2),
                    total_tickets=random.randint(5, 25),
                    high_risk_users=random.randint(2, 15)
                )
            )
        
        return stats

    async def get_risk_factors(self, user_id: str) -> Optional[dict]:
        db = get_database()
        collection = db["churn_predictions"]
        prediction = await collection.find_one({"user_id": user_id}, sort=[("created_at", -1)])
        if not prediction:
            return None
        return {
            "user_id": user_id,
            "risk_factors": prediction.get("risk_factors", []),
            "churn_probability": prediction.get("churn_probability", 0.0),
            "risk_level": prediction.get("risk_level", "LOW"),
            "last_updated": prediction.get("created_at")
        }


# 
# Crear instancia global del orquestador
# 
churn_service = ChurnService()
