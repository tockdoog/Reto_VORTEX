# =================================================================
# SERVICIO ORQUESTADOR DE CHURN
# =================================================================
# Este archivo COORDINA todo el flujo de predicciÃ³n de churn.
# Es el "manager" que usa el ML Service y guarda en MongoDB.

from datetime import datetime
from typing import Optional, List
from app.services.ml_service import ml_service
from app.db.mongodb import get_database
from app.models import ChurnPredictionModel, FeedbackModel
from app.schemas.churn import (
    PredictChurnRequest,
    PredictChurnResponse,
    ChurnStatusResponse,
    FeedbackRequest,
    FeedbackResponse,
    DailyChurnStatsResponse
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“š CONCEPTO: Orquestador (Orchestrator)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Un orquestador es como el "director de orquesta".
# Coordina diferentes servicios para completar una tarea.
#
# Flujo tÃ­pico:
# 1. Recibe datos del endpoint
# 2. Llama al ML Service para calcular
# 3. Guarda el resultado en MongoDB
# 4. Retorna la respuesta formateada
#
# Esto se conoce como "Separation of Concerns" (SeparaciÃ³n de Responsabilidades)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class ChurnService:
    """
    Servicio orquestador de Churn Prediction.
    
    Este servicio NO hace cÃ¡lculos de ML directamente.
    Coordina entre el MLService y la base de datos.
    """
    
    def __init__(self):
        """Constructor vacÃ­o. La configuraciÃ³n ya estÃ¡ en otros lados."""
        pass
        # 'pass' en Python significa "no hacer nada"
        # Equivalente en TS: constructor() { }
    
    
    async def predict_churn(
        self, 
        request: PredictChurnRequest
    ) -> PredictChurnResponse:
        """
        Predice el churn de un usuario y guarda el resultado.
        
        FLUJO:
        1. Llamar al ML Service para calcular
        2. Guardar la predicciÃ³n en MongoDB
        3. Retornar respuesta formateada
        """
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 1: Calcular probabilidad con el ML Service
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        churn_prob, risk_level, risk_factors = ml_service.predict_churn(
            request.features
        )
        # Esto DESEMPAQUETA la tupla en 3 variables separadas
        # En JS serÃ­a: const [prob, level, factors] = predict(...);
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 2: Generar recomendaciÃ³n
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        recommendation = ml_service.generate_recommendation(
            churn_prob,
            risk_level
        )
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 3: Guardar en MongoDB
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        db = get_database()
        collection = db["churn_predictions"]
        # En MongoDB, una "collection" es como una tabla SQL
        # Equivalente en SQL: SELECT * FROM churn_predictions
        
        prediction_doc = {
            "user_id": request.user_id,
            "churn_probability": churn_prob,
            "risk_level": risk_level,
            "risk_factors": risk_factors,
            "features_used": request.features,
            "model_version": ml_service.model_version,
            "created_at": datetime.utcnow()
        }
        
        # insert_one() guarda UN documento en MongoDB
        # 'await' espera a que termine de guardar
        await collection.insert_one(prediction_doc)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PASO 4: Retornar respuesta
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        return PredictChurnResponse(
            user_id=request.user_id,
            churn_probability=churn_prob,
            risk_level=risk_level,
            risk_factors=risk_factors,
            recommendation=recommendation,
            timestamp=datetime.utcnow()
        )
        # Esto crea una instancia del schema PredictChurnResponse
        # Pydantic validarÃ¡ automÃ¡ticamente que todo sea correcto
    
    
    async def get_churn_status(
        self, 
        user_id: str
    ) -> Optional[ChurnStatusResponse]:
        """
        Obtiene el Ãºltimo status de churn de un usuario.
        
        Este es el endpoint que el Dashboard llamarÃ¡ para saber
        si debe mostrar el popup de "Â¡No te vayas!"
        
        RETORNA:
        - ChurnStatusResponse si encuentra datos
        - None si el usuario no tiene predicciones
        """
        
        db = get_database()
        collection = db["churn_predictions"]
        
        # Buscar la predicciÃ³n MÃS RECIENTE de este usuario
        prediction = await collection.find_one(
            {"user_id": user_id},  # Filtro: WHERE user_id = ...
            sort=[("created_at", -1)]  # Ordenar por fecha DESC
        )
        # find_one() retorna UN solo documento (o None)
        # -1 significa DESCENDENTE (mÃ¡s reciente primero)
        # 1 serÃ­a ASCENDENTE (mÃ¡s antiguo primero)
        
        if not prediction:
            return None
            # Si no hay predicciÃ³n, retornar None (null en JS)
        
        # Si sÃ­ hay, formatear la respuesta
        show_popup = ml_service.should_show_exit_popup(
            prediction["churn_probability"]
        )
        
        popup_message = None
        if show_popup:
            popup_message = "Â¡Espera! Tenemos un 20% de descuento para ti ğŸ"
        
        return ChurnStatusResponse(
            user_id=user_id,
            churn_probability=prediction["churn_probability"],
            risk_level=prediction["risk_level"],
            last_updated=prediction["created_at"],
            show_exit_popup=show_popup,
            popup_message=popup_message
        )
    
    
    async def register_feedback(
        self, 
        request: FeedbackRequest
    ) -> FeedbackResponse:
        """
        Registra el feedback de una intervenciÃ³n.
        
        Cuando el usuario acepta/rechaza una oferta en el Dashboard,
        guardamos esa informaciÃ³n para mejorar el modelo en el futuro.
        """
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Buscar la Ãºltima predicciÃ³n para saber el score
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        db = get_database()
        predictions_coll = db["churn_predictions"]
        
        last_prediction = await predictions_coll.find_one(
            {"user_id": request.user_id},
            sort=[("created_at", -1)]
        )
        
        churn_prob = last_prediction["churn_probability"] if last_prediction else 0.0
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Guardar el feedback
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        feedback_coll = db["feedback"]
        
        feedback_doc = {
            "user_id": request.user_id,
            "prediction_churn_prob": churn_prob,
            "intervention_type": request.intervention_type,
            "user_action": request.user_action,
            "timestamp": datetime.utcnow()
        }
        
        await feedback_coll.insert_one(feedback_doc)
        
        return FeedbackResponse(
            message="Feedback registrado exitosamente",
            user_id=request.user_id,
            saved_at=datetime.utcnow()
        )
    
    
    async def get_daily_stats(
        self, 
        days: int = 30
    ) -> List[DailyChurnStatsResponse]:
        """
        Obtiene estadÃ­sticas diarias de churn.
        
        Este endpoint es para el grÃ¡fico de barras del Dashboard:
        "DÃ­as vs Probabilidad de churn y Tickets"
        
        PARÃMETROS:
        - days: CuÃ¡ntos dÃ­as hacia atrÃ¡s consultar (por defecto 30)
        
        RETORNA:
        Lista de estadÃ­sticas por dÃ­a.
        """
        
        # TODO: Implementar agregaciones de MongoDB
        # Por ahora retornamos datos dummy para que el Dashboard funcione
        
        from datetime import timedelta
        
        stats = []
        today = datetime.utcnow()
        
        for i in range(days):
            date = today - timedelta(days=i)
            
            # Generar datos aleatorios realistas
            import random
            stats.append(
                DailyChurnStatsResponse(
                    date=date.strftime("%Y-%m-%d"),
                    avg_churn_probability=round(random.uniform(0.4, 0.8), 2),
                    total_tickets=random.randint(5, 25),
                    high_risk_users=random.randint(2, 15)
                )
            )
        
        return stats


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Crear instancia global del orquestador
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
churn_service = ChurnService()
